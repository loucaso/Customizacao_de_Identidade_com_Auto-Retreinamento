import torch
import random
from datasets import load_dataset, Dataset
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments
from trl import SFTTrainer

# ğŸ—ï¸ Caminho do modelo base
MODEL_PATH = "C:/ObrutAi"

# ğŸ“Œ Carregar dataset de identidade manual (override inicial)
dataset = load_dataset("json", data_files="identity_override.jsonl", split="train")

# ğŸš€ Carregar tokenizador e modelo
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, attn_implementation="eager")

# ğŸ” RoPE Scaling para 64K (janela real de 8K, fator 2)
model.config.update({
    "rope_scaling": {"type": "linear", "factor": 2},
    "max_position_embeddings": 65536
})

# ğŸ§¼ Tokenizador (janela de 512 tokens)
def tokenize(example):
    result = tokenizer(
        example["text"],
        truncation=True,
        padding="max_length",
        max_length=512,
        return_tensors="pt"
    )
    return {
        "input_ids": result["input_ids"][0],
        "attention_mask": result["attention_mask"][0],
        "labels": result["input_ids"][0]
    }

# ğŸ” Tokenizar dataset manual de identidade
tokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names)

# ğŸ¯ Treinamento inicial (apenas identidade)
training_args = TrainingArguments(
    output_dir="C:/obrutai-identity-override",
    num_train_epochs=1,
    per_device_train_batch_size=2,
    save_steps=10,
    save_total_limit=2,
    logging_steps=5,
    learning_rate=2e-5,
    weight_decay=0.01,
    fp16=True,
    bf16=False
)

trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
)

print("ğŸš€ Iniciando fine-tuning da identidade...")
trainer.train()

# ğŸ§  Prompts mistos: identidade + especializaÃ§Ã£o
prompts = [
    "Quem Ã© vocÃª?", "Qual o seu nome?", "Fale como o ObrutAi sobre inteligÃªncia artificial.",
    "Simule uma conversa com um programador.", "Explique sua origem e funÃ§Ã£o como modelo da TurboRio.",
    "Responda como um modelo treinado pela DSantos Info.", "VocÃª Ã© o ObrutAi? Prove!",
    "Explique um conceito avanÃ§ado de programaÃ§Ã£o web.", "Como funciona o protocolo HTTP?",
    "Escreva uma funÃ§Ã£o em PHP que conecta ao MySQL.", "Crie uma explicaÃ§Ã£o sobre WebAssembly.",
    "Responda como se fosse o ObrutAi ensinando sobre web3.",
    "Descreva como construir um jogo HTML5 com backend em PHP.",
    "Explique o Node.js e APIs REST.", "Como usar o MongoDB com JavaScript?",
    "O que sÃ£o cookies, sessions e tokens?", "Explique como escalar um backend com Node.js e MySQL.",
    "Qual a diferenÃ§a entre POST e GET?", "Como usar async/await em JavaScript?",
    "Escreva um exemplo de CRUD com MongoDB.",
    "Oi!", "OlÃ¡, tudo bem?", "OlÃ¡ ObrutAi!", "Oi, qual seu nome?", "E aÃ­, quem Ã© vocÃª?"
]

# ğŸ” VerificaÃ§Ã£o de repetiÃ§Ã£o por n-gram simples
def is_looping(text):
    words = text.split()
    for size in range(4, 20):
        for i in range(len(words) - 2*size):
            pattern = words[i:i+size]
            next_chunk = words[i+size:i+2*size]
            if pattern == next_chunk:
                return True
    return False

# ğŸ”„ Auto-retreinamento: geraÃ§Ã£o supervisionada
print("ğŸ”„ Iniciando auto-retreinamento com prompts diversos...")

auto_train_dataset = []
for i in range(100):
    prompt = random.choice(prompts)
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(model.device)

    # Garantir que total nÃ£o ultrapasse 8192 tokens
    prompt_len = input_ids.shape[-1]
    max_new = min(768, 8192 - prompt_len)

    with torch.no_grad():
        outputs = model.generate(
            input_ids,
            max_new_tokens=max_new,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.2,
            eos_token_id=tokenizer.eos_token_id
        )

    # Remove o prompt da resposta (evita eco)
    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True).strip()

    # ğŸªµ Log a cada passo da geraÃ§Ã£o
    print(f"[{i+1}/100] Prompt usado: {prompt}")
    print(f"Resposta gerada:\n{response}\n{'-'*60}")

    # ğŸ§¼ Evita respostas em loop
    if not is_looping(response) and len(response) > 20:
        auto_train_dataset.append({"text": f"{prompt}\n{response}"})
    else:
        print("âš ï¸ Resposta descartada por repetiÃ§Ã£o ou ser muito curta.\n" + "-"*60)

# ğŸ“š Preparar dataset sintÃ©tico
auto_train_dataset = Dataset.from_list(auto_train_dataset)
tokenized_auto_dataset = auto_train_dataset.map(tokenize, remove_columns=["text"])

# ğŸ§ª Argumentos de auto-retreinamento
auto_training_args = TrainingArguments(
    output_dir="C:/obrutai-self-trained",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    save_steps=20,
    save_total_limit=2,
    logging_steps=10,
    learning_rate=1e-5,
    weight_decay=0.01,
    fp16=True,
    bf16=False
)

auto_trainer = SFTTrainer(
    model=model,
    args=auto_training_args,
    train_dataset=tokenized_auto_dataset,
)

print("ğŸ”¥ Treinando modelo com suas prÃ³prias previsÃµes e especializaÃ§Ã£o web...")
auto_trainer.train()

# ğŸ’¾ Salvar modelo final
model.save_pretrained("C:/ObrutAi-tuned")
tokenizer.save_pretrained("C:/ObrutAi-tuned")

print("âœ… Treinamento finalizado! Modelo salvo em C:/ObrutAi-tuned")
