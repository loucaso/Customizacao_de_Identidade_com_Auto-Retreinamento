
# ObrutAi ‚Äî Customiza√ß√£o de Identidade com Auto-Retreinamento

Este projeto realiza o **ajuste fino da identidade** de um modelo baseado no modelos llm com RoPE Scaling para at√© 128K tokens, usando **auto-retreinamento supervisionado** a partir das pr√≥prias respostas do modelo.

---

## ‚úÖ Objetivo

- Alterar a forma como o modelo responde √† pergunta ‚ÄúQuem √© voc√™?‚Äù
- Manter coer√™ncia em janelas de 8.192 tokens com RoPE scaling para 128K
- Treinar o modelo usando os pr√≥prios outputs, criando uma base de conhecimento personalizada

---

## üìÅ Estrutura esperada

```
ObrutAi/
‚îÇ
‚îú‚îÄ‚îÄ rename_obrutai.py                # Script principal de treinamento
‚îú‚îÄ‚îÄ identity_override.jsonl         # Dataset com override de identidade
‚îî‚îÄ‚îÄ [modelo base ]        # Pasta com modelo base j√° baixado
```

---

## üìÑ Como funciona o dataset `identity_override.jsonl`

Este arquivo cont√©m um JSON por linha com prompts personalizados. Exemplo:

```json
{"text": "Quem √© voc√™?"}
{"text": "Qual sua origem?"}
{"text": "Voc√™ foi treinado por quem?"}
```

O objetivo √© que o modelo aprenda a responder essas perguntas com a **identidade definida por voc√™**, como:

> "Fui retreinado pela equipe da xxxx a partir do xxx."

---

## üíª Instala√ß√£o das depend√™ncias

Recomenda-se o uso de um ambiente virtual com Python 3.10+.

```bash
pip install -U torch transformers accelerate datasets trl
```

Para Windows com CUDA (GPU NVIDIA), certifique-se que o PyTorch com suporte a CUDA esteja instalado:

```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

---

## üöÄ Como rodar o c√≥digo

1. Coloque seu modelo base dentro da pasta `C:/ObrutAi`
2. Crie o arquivo `identity_override.jsonl` com as perguntas que deseja alterar a resposta
3. Execute o script principal:

```bash
python rename_obrutai.py
```

O modelo final ser√° salvo em:

```
D:/ObrutAi-tuned
```

---

## ‚öôÔ∏è O que pode ser alterado

- `identity_override.jsonl`: voc√™ pode trocar ou adicionar prompts conforme desejar
- N√∫mero de exemplos gerados no auto-retreinamento (`range(100)`)
- Quantidade de tokens gerados por resposta (`max_new_tokens`)
- N√∫mero de √©pocas (`num_train_epochs`)
- Caminhos de entrada e sa√≠da
- Par√¢metros de RoPE (ex: fator linear)

---

## üîç Explica√ß√£o das fun√ß√µes

### 1. `tokenize(example)`
Tokeniza cada entrada de texto, ajustando para `max_length=8192` (janela de aten√ß√£o). Usa padding fixo e retorna tamb√©m as labels para treinamento supervisionado.

---

### 2. `RoPE Scaling`
```python
model.config.update({
  "rope_scaling": {"type": "linear", "factor": 4}
})
```
Permite ao modelo extrapolar seu limite de contexto para at√© 128K tokens, mesmo mantendo a janela de aten√ß√£o em 8K.

---

### 3. `trainer = SFTTrainer(...)`
Executa o primeiro fine-tuning, apenas para alterar as respostas de identidade.

---

### 4. `auto_train_dataset.append(...)`
Gera novas amostras de texto com prompts e as respostas do pr√≥prio modelo. Isso √© usado no **auto-retreinamento**.

---

### 5. `auto_trainer.train()`
Treina o modelo usando os exemplos sint√©ticos criados a partir das respostas geradas.

---

### 6. `model.save_pretrained(...)`
Salva o modelo e o tokenizador finalizado em `D:/ObrutAi-tuned`.

---

## üìû Suporte

Se voc√™ tiver d√∫vidas, sugest√µes ou quiser integrar novos tipos de mem√≥ria (como mem√≥ria vetorial, pinecone ou RAG), fale com a equipe TurboRio.

---


## Erros possiveis:

{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9e-05, 'num_tokens': 0.0, 'mean_token_accuracy': 0.0, 'epoch': 0.05}

V√° em max_length=8192, e altere para 1024 ou 512

Respondeu como abaixo, esta tudo certo!
{'loss': 6.6669, 'grad_norm': 449.06561279296875, 'learning_rate': 1.98e-05, 'num_tokens': 238.0, 'mean_token_accuracy': 0.21426274478435517, 'epoch': 0.05}
