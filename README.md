
# ObrutAi â€” CustomizaÃ§Ã£o de Identidade com Auto-Retreinamento

Este projeto realiza o **ajuste fino da identidade** de um modelo baseado no modelos llm com RoPE Scaling para atÃ© 128K tokens, usando **auto-retreinamento supervisionado** a partir das prÃ³prias respostas do modelo.

---

## âœ… Objetivo

- Alterar a forma como o modelo responde Ã  pergunta â€œQuem Ã© vocÃª?â€
- Manter coerÃªncia em janelas de 8.192 tokens com RoPE scaling para 128K
- Treinar o modelo usando os prÃ³prios outputs, criando uma base de conhecimento personalizada

---

## ğŸ“ Estrutura esperada

```
ObrutAi/
â”‚
â”œâ”€â”€ rename_obrutai.py                # Script principal de treinamento
â”œâ”€â”€ identity_override.jsonl         # Dataset com override de identidade
â””â”€â”€ [modelo base ]        # Pasta com modelo base jÃ¡ baixado
```

---

## ğŸ“„ Como funciona o dataset `identity_override.jsonl`

Este arquivo contÃ©m um JSON por linha com prompts personalizados. Exemplo:

```json
{"text": "Quem Ã© vocÃª?"}
{"text": "Qual sua origem?"}
{"text": "VocÃª foi treinado por quem?"}
```

O objetivo Ã© que o modelo aprenda a responder essas perguntas com a **identidade definida por vocÃª**, como:

> "Fui retreinado pela equipe da xxxx a partir do xxx."

---

## ğŸ’» InstalaÃ§Ã£o das dependÃªncias

Recomenda-se o uso de um ambiente virtual com Python 3.10+.

```bash
pip install -U torch transformers accelerate datasets trl
```

Para Windows com CUDA (GPU NVIDIA), certifique-se que o PyTorch com suporte a CUDA esteja instalado:

```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸš€ Como rodar o cÃ³digo

1. Coloque seu modelo base dentro da pasta `C:/ObrutAi`
2. Crie o arquivo `identity_override.jsonl` com as perguntas que deseja alterar a resposta
3. Execute o script principal:

```bash
python rename_obrutai.py
```

O modelo final serÃ¡ salvo em:

```
D:/ObrutAi-tuned
```

---

## âš™ï¸ O que pode ser alterado

- `identity_override.jsonl`: vocÃª pode trocar ou adicionar prompts conforme desejar
- NÃºmero de exemplos gerados no auto-retreinamento (`range(100)`)
- Quantidade de tokens gerados por resposta (`max_new_tokens`)
- NÃºmero de Ã©pocas (`num_train_epochs`)
- Caminhos de entrada e saÃ­da
- ParÃ¢metros de RoPE (ex: fator linear)

---

## ğŸ” ExplicaÃ§Ã£o das funÃ§Ãµes

### 1. `tokenize(example)`
Tokeniza cada entrada de texto, ajustando para `max_length=8192` (janela de atenÃ§Ã£o). Usa padding fixo e retorna tambÃ©m as labels para treinamento supervisionado.

---

### 2. `RoPE Scaling`
```python
model.config.update({
  "rope_scaling": {"type": "linear", "factor": 4}
})
```
Permite ao modelo extrapolar seu limite de contexto para atÃ© 128K tokens, mesmo mantendo a janela de atenÃ§Ã£o em 8K.

---

### 3. `trainer = SFTTrainer(...)`
Executa o primeiro fine-tuning, apenas para alterar as respostas de identidade.

---

### 4. `auto_train_dataset.append(...)`
Gera novas amostras de texto com prompts e as respostas do prÃ³prio modelo. Isso Ã© usado no **auto-retreinamento**.

---

### 5. `auto_trainer.train()`
Treina o modelo usando os exemplos sintÃ©ticos criados a partir das respostas geradas.

---

### 6. `model.save_pretrained(...)`
Salva o modelo e o tokenizador finalizado em `D:/ObrutAi-tuned`.

---

## ğŸ“ Suporte

Se vocÃª tiver dÃºvidas, sugestÃµes ou quiser integrar novos tipos de memÃ³ria (como memÃ³ria vetorial, pinecone ou RAG), fale com a equipe TurboRio.

---
